{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "import math\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Our utilities\n",
    "from Utils import *\n",
    "from FinancialMetrics import *\n",
    "from Momentum import *\n",
    "from TitleOutOfMarket import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants\n",
    "The CSV files must be in the same directory of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROLLING_WINDOW_SIZE = 180   # Number of days to consider in our regression\n",
    "NUMBER_OF_TITLES = 10       # Number of titles inside the portfolio\n",
    "\n",
    "CLOSING_PRICE_CSV = 'data/NASDAQ-100-CLOSING-PRICES.csv'\n",
    "TBILL_CSV = 'data/13WEEKTBILLCOUPON.csv' \n",
    "CLOSING_PRICE_OF_REMOVED_CSV = 'data/CLOSING_PRICES_OF_REMOVED_TITLES.csv' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing\n",
    "Loading the closing prices dataset. We then calculate log returns \n",
    "\n",
    "### Load the Closing Price Dataset\n",
    "Historical closing prices (with titles swap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "closing_prices = pd.read_csv(CLOSING_PRICE_CSV)\n",
    "closing_prices.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the log returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasdaq100_returns = get_log_returns(CLOSING_PRICE_CSV)\n",
    "nasdaq100_returns.fillna(np.nan, inplace=True)\n",
    "nasdaq100_returns.head()\n",
    "nasdaq100_returns.head().style.applymap(color_negative_red)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Closing Price Dataset of stock removed from the Nasdaq-100 Index\n",
    "Historical prices of removed titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "closing_prices_removed_titles = pd.read_csv(CLOSING_PRICE_OF_REMOVED_CSV)\n",
    "closing_prices_removed_titles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Risk Free Asset (US Treasury Bill - 3 Months)\n",
    "We've used the Coupon Equivalent. The Coupon Equivalent, also called the Bond Equivalent, or the Investment Yield, is the bill's yield based on the purchase price, discount, and a 365- or 366-day year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbill = pd.read_csv(TBILL_CSV)\n",
    "tbill['DATE'] = pd.to_datetime(tbill['DATE'])\n",
    "tbill = tbill.sort_values(by='DATE', ascending=True)\n",
    "tbill = tbill.reset_index().drop(['index'], axis=1)\n",
    "risk_free_rate = tbill['13 WEEKS COUPON EQUIVALENT'].mean()\n",
    "print(f'Annual risk-free rate: {np.round(risk_free_rate, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling Linear Regression\n",
    "We create a dataframe containing the ROLLING_WINDOW_SIZE (defult 6-month) rows of the returns dataframe based on a given starting day. In this dataframe will be removed all those titles that possibly entered or exited in that period (have nan values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_window_returns(days):\n",
    "    window_returns = nasdaq100_returns.iloc[days: days + ROLLING_WINDOW_SIZE]\n",
    "    window_returns = window_returns.reset_index().drop(['index'], axis=1)\n",
    "\n",
    "    # Remove titles that are not in the Nasdaq-100 window range\n",
    "    window_returns.dropna(axis=1, how='any', inplace=True)\n",
    "\n",
    "    # Get the name of the columns\n",
    "    titles = window_returns.columns.tolist()\n",
    "\n",
    "    # Remove the first two element (Dates, NDX Index) because I don't need them\n",
    "    titles = titles[2:]\n",
    "\n",
    "    return window_returns, titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: First 180 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_df, titles = get_window_returns(0)\n",
    "print(\"In the first {} days, {} stocks will be taken from the index and analyzed.\".format(ROLLING_WINDOW_SIZE, len(rolling_df.columns)))\n",
    "rolling_df.head().style.applymap(color_negative_red)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TITOLO GENERALE: TO REORDER\n",
    "- returns calculator\n",
    "- portfolio ranking\n",
    "- portfolio builder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portfolio Implementation\n",
    "\n",
    "AGGIUNGERE DESCRIZIONE\n",
    "\n",
    "- TODO: RITORNARE ANCHE rank_df per fare dopo eventuali analisi nel report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def portfolio_ranked(selector, days):\n",
    "    \"\"\"\n",
    "    Build a portfolio, based on the selector, by taking the titles included in the index in the range [days; days + ROLLING_WINDOW_SIZE]\n",
    "    :param selector: The selector to use in order to build the rank and select the titles\n",
    "    :param selector_columns: Optional values to use in the specific selector\n",
    "    :param days: The number of days to skip \n",
    "    \"\"\"\n",
    "    \n",
    "    rolling_df, titles = get_window_returns(days)\n",
    "    rank_df = pd.DataFrame(columns=['Title', 'r2', 'specific_risk', 'beta', 'alpha', 'alpha_significance', 'absolute_returns', 'systematic_risk'])\n",
    "\n",
    "    ndx_returns = rolling_df.iloc[:, 1].values\n",
    "\n",
    "    for title in titles:\n",
    "        title_returns = rolling_df.iloc[0 : ROLLING_WINDOW_SIZE, rolling_df.columns.get_loc(title)]\n",
    "\n",
    "        ndx_returns = sm.add_constant(ndx_returns)\n",
    "        model = sm.OLS(title_returns, ndx_returns)\n",
    "        result = model.fit()\n",
    "\n",
    "        rank_df = rank_df.append({'Title': title, 'r2': result.rsquared, 'specific_risk': np.var(result.resid), 'beta': result.params[1], 'alpha': result.params[0], 'alpha_significance': result.pvalues[0], 'absolute_returns': np.sum(title_returns),  'systematic_risk': result.params[1] ** 2 * np.var(ndx_returns)}, ignore_index=True)\n",
    "        rank_df['total_risk'] = rank_df['systematic_risk'] + rank_df['specific_risk']\n",
    "\n",
    "    full_rank_df = rank_df.copy()\n",
    "    if selector == 'max_r2':\n",
    "        winners = rank_df.sort_values(by='r2', ascending=False).head(NUMBER_OF_TITLES)\n",
    "        selected_titles = winners['Title'].tolist()\n",
    "    elif selector == 'max_total_risk':\n",
    "        winners = rank_df.sort_values(by='total_risk', ascending=False).head(NUMBER_OF_TITLES)\n",
    "        selected_titles = winners['Title'].tolist()\n",
    "    elif selector == 'min_total_risk':\n",
    "        winners = rank_df.sort_values(by='total_risk', ascending=True).head(NUMBER_OF_TITLES)\n",
    "        selected_titles = winners['Title'].tolist()\n",
    "    elif selector == 'excess_return_over_total':\n",
    "        rank_df['excess_over_total'] = rank_df['alpha'] / rank_df['absolute_returns']\n",
    "        winners = rank_df.sort_values(by='excess_over_total', ascending=True).head(NUMBER_OF_TITLES)\n",
    "        selected_titles = winners['Title'].tolist()\n",
    "    elif selector == 'max_specific_risk':\n",
    "        winners = rank_df.sort_values(by='specific_risk', ascending=False).head(NUMBER_OF_TITLES)\n",
    "        selected_titles = winners['Title'].tolist()\n",
    "    elif selector == 'absolute_returns':\n",
    "        winners = rank_df.sort_values(by='absolute_returns', ascending=False).head(NUMBER_OF_TITLES)\n",
    "        selected_titles = winners['Title'].tolist()\n",
    "    elif selector == 'max_beta':\n",
    "        # The same as high_systematic_risk\n",
    "        winners = rank_df.sort_values(by='beta', ascending=False).head(NUMBER_OF_TITLES)\n",
    "        selected_titles = winners['Title'].tolist()\n",
    "    elif selector == 'positive_alpha':\n",
    "        winners = rank_df.sort_values(by='alpha', ascending=True).head(NUMBER_OF_TITLES)\n",
    "        selected_titles = winners['Title'].tolist()\n",
    "    elif selector == 'min_r2_and_high_specific_risk':\n",
    "        rank_df = rank_df.sort_values(by=['r2'], ascending=True)\n",
    "        rank_df = rank_df.head(int(len(titles) * 1/3))\n",
    "        winners = rank_df.sort_values(by='specific_risk', ascending=False).head(NUMBER_OF_TITLES)\n",
    "        selected_titles = winners['Title'].tolist()\n",
    "    elif selector == 'min_beta':\n",
    "        winners = rank_df.sort_values(by='beta', ascending=True).head(NUMBER_OF_TITLES)\n",
    "        selected_titles = winners['Title'].tolist()\n",
    "    elif selector == 'high_systematic_risk' or selector == 'low_systematic_risk':\n",
    "        ascending = False\n",
    "        if 'low' in selector:\n",
    "            ascending = True\n",
    "        winners = rank_df.sort_values(by='systematic_risk', ascending=ascending).head(NUMBER_OF_TITLES)\n",
    "        selected_titles = winners['Title'].tolist()\n",
    "    elif selector == 'positive_and_significant_alpha':\n",
    "        rank_df = rank_df[rank_df['alpha_significance'] < 0.05]\n",
    "        rank_df = rank_df[rank_df['alpha'] > 0]\n",
    "        if(rank_df.shape[0] < NUMBER_OF_TITLES):\n",
    "            raise Exception(\"Not enought titles\")\n",
    "        winners = rank_df.sort_values(by='alpha', ascending=False).head(NUMBER_OF_TITLES)\n",
    "        selected_titles = winners['Title'].tolist()\n",
    "    elif selector == 'positive_alpha_and_high_beta':\n",
    "        rank_df = rank_df[rank_df['alpha'] > 0]\n",
    "        winners = rank_df.sort_values(by='beta', ascending=False).head(NUMBER_OF_TITLES)\n",
    "        selected_titles = winners['Title'].tolist()\n",
    "    \n",
    "    return selected_titles, winners, full_rank_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weekly_portfolio_returns(window_returns):\n",
    "    \n",
    "    returns = []\n",
    "    left_the_market = [] # Keep here title already out of the portfolio\n",
    "\n",
    "    for index, row in window_returns.iterrows():\n",
    "\n",
    "        portfolio_components_number = NUMBER_OF_TITLES\n",
    "        daily_return = 0\n",
    "\n",
    "        for title, value in row.items():\n",
    "            if math.isnan(value):\n",
    "                if title in left_the_market:\n",
    "                    portfolio_components_number -= 1 # Skip this title. Removed from the market and from the portfolio\n",
    "                else:\n",
    "                    missing_date = nasdaq100_returns.iloc[index - 1]['Dates'] # Lo slicing di pandas sugli object ritorna l'indice + 1\n",
    "                    missing_price = closing_prices_removed_titles.iloc[index][title]\n",
    "\n",
    "                    if math.isnan(missing_price):\n",
    "                        #print(f'{title} is Nan at row {index} ({missing_date}). It was removed')\n",
    "\n",
    "                        if title in title_out_of_the_market.keys():\n",
    "                            missing_price = title_out_of_the_market[title]\n",
    "                            last_closing_price = closing_prices_removed_titles.iloc[index - 1][title]\n",
    "                            missing_return = np.log(missing_price) - np.log(last_closing_price)\n",
    "                            daily_return += missing_return\n",
    "                        else:\n",
    "                            raise Exception(f'Cannot find the closing/acquisition price of {title}')   \n",
    "\n",
    "                        left_the_market.append(title)\n",
    "                    else:\n",
    "                        last_closing_price = closing_prices_removed_titles.iloc[index - 1][title]\n",
    "                        missing_return = np.log(missing_price) - np.log(last_closing_price)\n",
    "                        daily_return += missing_return\n",
    "            else:\n",
    "                 daily_return += value\n",
    "\n",
    "        #if portfolio_components_number < NUMBER_OF_TITLES:\n",
    "            #print(f'Last return: {returns[-1]}. New return: {daily_return / portfolio_components_number}. Number of titles {portfolio_components_number}')\n",
    "            \n",
    "        returns.append(daily_return / portfolio_components_number)\n",
    "            \n",
    "    return returns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def portfolio_builder(selector):\n",
    "    portfolio_returns = []\n",
    "    portfolio = pd.DataFrame(columns=['Dates'] + [f'Title{i}' for i in range(1 , NUMBER_OF_TITLES + 1)] + ['Returns'])\n",
    "    portfolio_history = pd.DataFrame(columns=['Dates', 'Title', 'r2', 'specific_risk', 'beta', 'alpha', 'alpha_significance', 'absolute_returns'])\n",
    "\n",
    "    titles, values, _ = portfolio_ranked(selector, 0)\n",
    "    portfolio_history = portfolio_history.append(values, ignore_index=True)\n",
    "       \n",
    "    days_range = nasdaq100_returns.shape[0] - ROLLING_WINDOW_SIZE\n",
    "    for days in range(7, days_range, 7):\n",
    "\n",
    "        nasdaq100_window_returns = nasdaq100_returns[titles].iloc[ROLLING_WINDOW_SIZE + days - 7 : ROLLING_WINDOW_SIZE + days]\n",
    "\n",
    "        tmp_returns = get_weekly_portfolio_returns(nasdaq100_window_returns)\n",
    "        portfolio_returns = portfolio_returns + tmp_returns\n",
    "\n",
    "        portfolio_row = {'Dates': nasdaq100_returns.iloc[ROLLING_WINDOW_SIZE + days]['Dates']}\n",
    "        portfolio_row.update({f'Title{i}': titles[i - 1] for i in range(1, NUMBER_OF_TITLES + 1)})\n",
    "        portfolio = portfolio.append(portfolio_row, ignore_index=True)\n",
    "        titles, values, _ = portfolio_ranked(selector, days)\n",
    "        portfolio_history = portfolio_history.append(values, ignore_index=True)\n",
    "\n",
    "    portfolio_history = portfolio_history[:-NUMBER_OF_TITLES]\n",
    "    dates = np.array(portfolio['Dates'])\n",
    "    dates = np.repeat(dates, NUMBER_OF_TITLES)\n",
    "    portfolio_history['Dates'] = dates\n",
    "    return portfolio, portfolio_returns, portfolio_history\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portfolio Selectors\n",
    "- max_r2: desc..\n",
    "\n",
    "DESCRIVERE I SELETTORI\n",
    "E POI DARE UNA DESCRIZIONE A TUTTI I VARI DICTIONARY CHE CREIAMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectors = [\n",
    "    'max_r2',\n",
    "    'absolute_returns',\n",
    "    'min_r2_and_high_specific_risk', \n",
    "    'max_specific_risk',\n",
    "    'high_systematic_risk',\n",
    "    'low_systematic_risk',\n",
    "    'min_beta', \n",
    "    'positive_alpha',\n",
    "    'positive_and_significant_alpha',\n",
    "    'positive_alpha_and_high_beta',\n",
    "    'max_total_risk',\n",
    "    'min_total_risk',\n",
    "    'excess_return_over_total'\n",
    "]\n",
    "\n",
    "selectors = ['absolute_returns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_metrics = pd.DataFrame(columns=['Portfolio Title', 'Annualized Returns', 'Annualized Volatility'])\n",
    "advanced_metrics = pd.DataFrame(columns=['Portfolio Title', 'Sharpe Ratio', 'MDD', 'CL', 'Var 90', 'Var 95', 'Var 99', 'IR', 'M2'])\n",
    "portfolios_selector_history = {}\n",
    "portfolios_analysis = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_limit = 0\n",
    "for i in range(7, nasdaq100_returns.shape[0] - 180, 7):\n",
    "    days_limit = i\n",
    "ndx_returns = nasdaq100_returns[180: days_limit + 180]['NDX Index'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for selector in selectors:\n",
    "    try:\n",
    "        print(f'Buildindg {selector} portfolio')        \n",
    "\n",
    "        portfolio, returns, history = portfolio_builder(selector)\n",
    "        \n",
    "        portfolios_selector_history[selector] = history\n",
    "        portfolios_analysis[selector] = returns\n",
    "\n",
    "        basic_row = get_base_metrics(selector, returns)\n",
    "        base_metrics = base_metrics.append(basic_row, ignore_index=True)\n",
    "        advanced_row = get_advanced_metrics(selector, returns, ndx_returns, risk_free_rate)\n",
    "        advanced_metrics = advanced_metrics.append(advanced_row, ignore_index=True)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'Cannot build the portfolio for the selector {selector}: {str(e)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the Nasdaq-100 to our tables\n",
    "basic_row = get_base_metrics('Nasdaq-100', ndx_returns)\n",
    "base_metrics = base_metrics.append(basic_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tabulate(base_metrics, headers='keys', tablefmt='psql')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tabulate(advanced_metrics, headers='keys', tablefmt='psql')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of some results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Portfolio with the highest level of R-squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0 # Play with this\n",
    "portfolios_selector_history['max_r2'].iloc[idx : idx + 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = portfolios_selector_history['max_r2']['r2'].mean()\n",
    "print(f'The average value of r-squared is: {np.round(mean, 4)}')\n",
    "\n",
    "portfolios_selector_history['max_r2'].sort_values(by='r2', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Portfolio of stock with better absolute return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0 # Play with this\n",
    "portfolios_selector_history['absolute_returns'].iloc[idx : idx + 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First week\n",
    "first_week_return = pd.DataFrame()\n",
    "first_week_return['Date'] = nasdaq100_returns[180:187]['Dates']\n",
    "first_week_return['Log Return'] = np.array(portfolios_analysis['absolute_returns'][idx : idx + 7])\n",
    "first_week_return['Log Return'] = first_week_return['Log Return']\n",
    "first_week_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = list(portfolios_selector_history['absolute_returns'][0:10]['Title'])\n",
    "first_week_stocks_return = nasdaq100_returns[titles].iloc[ROLLING_WINDOW_SIZE + 7 - 7 : ROLLING_WINDOW_SIZE + 7]\n",
    "first_week_stocks_return.style.applymap(color_negative_red)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def portfolios_comparison(money, portfolios):\n",
    "    dates = np.array(nasdaq100_returns[181:]['Dates']) \n",
    "    ndx_returns = np.array(nasdaq100_returns[181:]['NDX Index'])\n",
    "    \n",
    "    returns = []\n",
    "    dates_to_show = [dates[i] for i in np.linspace(0, len(dates) - 1, 20).astype(int)]\n",
    "\n",
    "    returns.append(money * math.exp(ndx_returns[0]))\n",
    "    for i in range(1, len(dates)):\n",
    "        returns.append(returns[i-1] * math.exp(ndx_returns[i]))\n",
    "\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.plot(dates, returns, label='NDX Index')\n",
    "\n",
    "    for title, portfolio_returns in portfolios.items():\n",
    "        returns = []\n",
    "        returns.append(money * math.exp(portfolio_returns[0]))\n",
    "        for i in range(1, len(dates)):\n",
    "            returns.append(returns[i-1] * math.exp(portfolio_returns[i]))\n",
    "        plt.plot(dates, returns, label=title)\n",
    "\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.xticks(dates_to_show, rotation=45)\n",
    "    plt.ylabel(\"Value ($)\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Portfolios Comparison\")\n",
    "    # Aggiungere legenda log return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolios_comparison(1000, portfolios_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndx_investment_returns = cumulative_returns(np.array(ndx_returns)) * 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(18,9)})\n",
    "dates = np.array(nasdaq100_returns[ROLLING_WINDOW_SIZE: ROLLING_WINDOW_SIZE + days_limit]['Dates']) \n",
    "dates_to_show = [dates[i] for i in np.linspace(0, len(dates) - 1, 20).astype(int)]\n",
    "l = sns.lineplot(x = dates, y = ndx_investment_returns, linewidth = 1.5)\n",
    "l.yaxis.tick_right()\n",
    "l.set_xticks(dates_to_show)\n",
    "l.set_xticklabels(dates_to_show, rotation=45)\n",
    "l.set_title('NDX')\n",
    "l.legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxr2_investment_returns = cumulative_returns(np.array(portfolios_analysis['max_r2'])) * 1000\n",
    "sns.set(font=\"Verdana\")\n",
    "sns.set(rc={'figure.figsize':(18,9)})\n",
    "dates = np.array(nasdaq100_returns[ROLLING_WINDOW_SIZE: ROLLING_WINDOW_SIZE + days_limit]['Dates']) \n",
    "dates_to_show = [dates[i] for i in np.linspace(0, len(dates) - 1, 20).astype(int)]\n",
    "l = sns.lineplot(x = dates, y = ndx_investment_returns, linewidth = 1.5)\n",
    "l1 = sns.lineplot(x = dates, y = maxr2_investment_returns, linewidth = 1.5)\n",
    "l.yaxis.tick_right()\n",
    "l.set_xticks(dates_to_show)\n",
    "l.set_xticklabels(dates_to_show, rotation=45)\n",
    "l.set_xlabel('Dates')\n",
    "l.set_ylabel('Value of investment ($)')\n",
    "l.set_title('NDX VS MAX R2 PORTFOLIO', size=14)\n",
    "l.legend(labels=['NDX', 'MAX R2'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxr2_investment_returns = cumulative_returns(np.array(portfolios_analysis['max_specific_risk'])) * 1000\n",
    "sns.set(font=\"Verdana\")\n",
    "sns.set(rc={'figure.figsize':(18,9)})\n",
    "dates = np.array(nasdaq100_returns[ROLLING_WINDOW_SIZE: ROLLING_WINDOW_SIZE + days_limit]['Dates']) \n",
    "dates_to_show = [dates[i] for i in np.linspace(0, len(dates) - 1, 20).astype(int)]\n",
    "l = sns.lineplot(x = dates, y = ndx_investment_returns, linewidth = 1.5, color='blue')\n",
    "l1 = sns.lineplot(x = dates, y = maxr2_investment_returns, linewidth = 1.5, color='red')\n",
    "l.yaxis.tick_right()\n",
    "l.set_xticks(dates_to_show)\n",
    "l.set_xticklabels(dates_to_show, rotation=45)\n",
    "l.set_xlabel('Dates')\n",
    "l.set_ylabel('Value of investment ($)')\n",
    "l.set_title('NDX VS MAX SPECIFIC RISK PORTFOLIO', size=14)\n",
    "l.legend(labels=['NDX', 'MAX SPECIFIC RISK'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non Compulsoty Tasks\n",
    "- Momentum implmentation\n",
    "- A different weights schema: Inverse Volatility\n",
    "- Simple Returns vs Log Returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Momentum\n",
    "Momentum strategy is a system of buying stocks or other securities that have had high returns over the past months. There are several ways to implement a momentum strategy. In this notebook we decide to implement the Clenow Momentum (by Andreas F. Clenow). We take 1/3 of the entire titles on the basis of momentum and then we redo the calculations done previously - but on a subset.\n",
    "\n",
    "For more details:\n",
    "- https://www.amazon.com/Stocks-Move-Beating-Momentum-Strategies/dp/1511466146\n",
    "- https://www.quant-investing.com/blog/this-easy-to-use-adjusted-slope-momentum-strategy-performed-7-times-better-than-the-market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reinitialization\n",
    "base_metrics = pd.DataFrame(columns=['Portfolio Title', 'Annualized Returns', 'Annualized Volatility'])\n",
    "advanced_metrics = pd.DataFrame(columns=['Portfolio Title', 'Sharpe Ratio', 'MDD', 'CL', 'Var 90', 'Var 95', 'Var 99', 'IR', 'M2'])\n",
    "portfolios_selector_history = {}\n",
    "portfolios_analysis = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Core part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clenow_momentum(title, days):\n",
    "    prices = closing_prices[title].iloc[days: days + ROLLING_WINDOW_SIZE]\n",
    "    prices_log = np.log(prices)\n",
    "    x = np.arange(len(prices_log)) \n",
    "    slope, _, rvalue, _, _ = linregress(x, prices_log)\n",
    "    m = ((1 + slope) ** 252) * (rvalue ** 2)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_window_returns_with_momentum(days):\n",
    "    window_returns = nasdaq100_returns.iloc[days: days + ROLLING_WINDOW_SIZE]\n",
    "    window_returns = window_returns.reset_index().drop(['index'], axis=1)\n",
    "\n",
    "    window_returns.dropna(axis=1, how='any', inplace=True)\n",
    "    titles = window_returns.columns.tolist()\n",
    "    titles = titles[2:]\n",
    "\n",
    "    momentums = pd.DataFrame(columns=['Title', 'Momentum'])\n",
    "    momentums['Title'] = titles\n",
    "\n",
    "    for index, tt in momentums.iterrows():\n",
    "        momentums.at[index,'Momentum'] = get_clenow_momentum(tt.Title, days)\n",
    "\n",
    "    # Get first 1/3 titles with the highest momentum\n",
    "    momentums = momentums.sort_values(by='Momentum', ascending=False)\n",
    "    momentums = momentums.iloc[:int(len(momentums) / 3)]\n",
    "    momentums = momentums['Title'].tolist()\n",
    "\n",
    "\n",
    "    return window_returns, momentums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def portfolio_ranked_with_momentum(selector, days):\n",
    "\n",
    "    rolling_df, titles = get_window_returns_with_momentum(days) \n",
    "\n",
    "    rank_df = pd.DataFrame(columns=['Title', 'r2', 'specific_risk', 'beta', 'alpha', 'alpha_significance', 'absolute_returns', 'systematic_risk'])\n",
    "\n",
    "    ndx_returns = rolling_df.iloc[:, 1].values\n",
    "\n",
    "    for title in titles:\n",
    "        title_returns = rolling_df.iloc[0 : ROLLING_WINDOW_SIZE, rolling_df.columns.get_loc(title)]\n",
    "\n",
    "        ndx_returns = sm.add_constant(ndx_returns)\n",
    "        model = sm.OLS(title_returns, ndx_returns)\n",
    "        result = model.fit()\n",
    "\n",
    "        rank_df = rank_df.append({'Title': title, 'r2': result.rsquared, 'specific_risk': np.var(result.resid), 'beta': result.params[1], 'alpha': result.params[0], 'alpha_significance': result.pvalues[0], 'absolute_returns': np.sum(title_returns),  'systematic_risk': result.params[1] ** 2 * np.var(ndx_returns)}, ignore_index=True)\n",
    "        rank_df['total_risk'] = rank_df['systematic_risk'] + rank_df['specific_risk']\n",
    "\n",
    "    full_rank_df = rank_df.copy()\n",
    "    if selector == 'max_r2':\n",
    "        winners = rank_df.sort_values(by='r2', ascending=False).head(NUMBER_OF_TITLES)\n",
    "        selected_titles = winners['Title'].tolist()\n",
    "    elif selector == 'max_total_risk':\n",
    "        winners = rank_df.sort_values(by='total_risk', ascending=False).head(NUMBER_OF_TITLES)\n",
    "        selected_titles = winners['Title'].tolist()\n",
    "    elif selector == 'min_total_risk':\n",
    "        winners = rank_df.sort_values(by='total_risk', ascending=True).head(NUMBER_OF_TITLES)\n",
    "        selected_titles = winners['Title'].tolist()\n",
    "    elif selector == 'excess_return_over_total':\n",
    "        rank_df['excess_over_total'] = rank_df['alpha'] / rank_df['absolute_returns']\n",
    "        winners = rank_df.sort_values(by='excess_over_total', ascending=True).head(NUMBER_OF_TITLES)\n",
    "        selected_titles = winners['Title'].tolist()\n",
    "    elif selector == 'max_specific_risk':\n",
    "        winners = rank_df.sort_values(by='specific_risk', ascending=False).head(NUMBER_OF_TITLES)\n",
    "        selected_titles = winners['Title'].tolist()\n",
    "    elif selector == 'absolute_returns':\n",
    "        winners = rank_df.sort_values(by='absolute_returns', ascending=False).head(NUMBER_OF_TITLES)\n",
    "        selected_titles = winners['Title'].tolist()\n",
    "    elif selector == 'max_beta':\n",
    "        # The same as high_systematic_risk\n",
    "        winners = rank_df.sort_values(by='beta', ascending=False).head(NUMBER_OF_TITLES)\n",
    "        selected_titles = winners['Title'].tolist()\n",
    "    elif selector == 'positive_alpha':\n",
    "        winners = rank_df.sort_values(by='alpha', ascending=True).head(NUMBER_OF_TITLES)\n",
    "        selected_titles = winners['Title'].tolist()\n",
    "    elif selector == 'min_r2_and_high_specific_risk':\n",
    "        rank_df = rank_df.sort_values(by=['r2'], ascending=True)\n",
    "        rank_df = rank_df.head(int(len(titles) * 1/3))\n",
    "        winners = rank_df.sort_values(by='specific_risk', ascending=False).head(NUMBER_OF_TITLES)\n",
    "        selected_titles = winners['Title'].tolist()\n",
    "    elif selector == 'min_beta':\n",
    "        winners = rank_df.sort_values(by='beta', ascending=True).head(NUMBER_OF_TITLES)\n",
    "        selected_titles = winners['Title'].tolist()\n",
    "    elif selector == 'high_systematic_risk' or selector == 'low_systematic_risk':\n",
    "        ascending = False\n",
    "        if 'low' in selector:\n",
    "            ascending = True\n",
    "        winners = rank_df.sort_values(by='systematic_risk', ascending=ascending).head(NUMBER_OF_TITLES)\n",
    "        selected_titles = winners['Title'].tolist()\n",
    "    elif selector == 'positive_and_significant_alpha':\n",
    "        rank_df = rank_df[rank_df['alpha_significance'] < 0.05]\n",
    "        rank_df = rank_df[rank_df['alpha'] > 0]\n",
    "        if(rank_df.shape[0] < NUMBER_OF_TITLES):\n",
    "            raise Exception(\"Not enought titles\")\n",
    "        winners = rank_df.sort_values(by='alpha', ascending=False).head(NUMBER_OF_TITLES)\n",
    "        selected_titles = winners['Title'].tolist()\n",
    "    elif selector == 'positive_alpha_and_high_beta':\n",
    "        rank_df = rank_df[rank_df['alpha'] > 0]\n",
    "        winners = rank_df.sort_values(by='beta', ascending=False).head(NUMBER_OF_TITLES)\n",
    "        selected_titles = winners['Title'].tolist()\n",
    "    \n",
    "    return selected_titles, winners, full_rank_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def portfolio_builder_with_momentum(selector):\n",
    "    portfolio_returns = []\n",
    "    portfolio = pd.DataFrame(columns=['Dates'] + [f'Title{i}' for i in range(1,11)] + ['Returns'])\n",
    "    portfolio_history = pd.DataFrame(columns=['Dates', 'Title', 'r2', 'specific_risk', 'beta', 'alpha', 'alpha_significance', 'absolute_returns'])\n",
    "\n",
    "    titles, values, _ = portfolio_ranked_with_momentum(selector, 0)\n",
    "    portfolio_history = portfolio_history.append(values, ignore_index=True)\n",
    "       \n",
    "    days_range = nasdaq100_returns.shape[0] - ROLLING_WINDOW_SIZE\n",
    "    for days in range(7, days_range, 7):\n",
    "\n",
    "        nasdaq100_window_returns = nasdaq100_returns[titles].iloc[ROLLING_WINDOW_SIZE + days - 7 : ROLLING_WINDOW_SIZE + days]\n",
    "\n",
    "        tmp_returns = get_weekly_portfolio_returns(nasdaq100_window_returns)\n",
    "        portfolio_returns = portfolio_returns + tmp_returns\n",
    "\n",
    "        portfolio_row = {'Dates': nasdaq100_returns.iloc[ROLLING_WINDOW_SIZE + days]['Dates']}\n",
    "        portfolio_row.update({f'Title{i}': titles[i - 1] for i in range(1,11)})\n",
    "        portfolio = portfolio.append(portfolio_row, ignore_index=True)\n",
    "\n",
    "        titles, values, _ = portfolio_ranked_with_momentum(selector, days)\n",
    "        portfolio_history = portfolio_history.append(values, ignore_index=True)\n",
    "\n",
    "    portfolio_history = portfolio_history[:-10]\n",
    "    dates = np.array(portfolio['Dates'])\n",
    "    dates = np.repeat(dates, 10)\n",
    "    portfolio_history['Dates'] = dates\n",
    "    return portfolio, portfolio_returns, portfolio_history\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for selector in selectors:\n",
    "    try:\n",
    "        print(f'Buildindg {selector} portfolio')        \n",
    "        portfolio, returns, history = portfolio_builder_with_momentum(selector)\n",
    "        portfolios_selector_history[selector] = history\n",
    "        portfolios_analysis[selector] = returns\n",
    "        basic_row = get_base_metrics(selector, returns)\n",
    "        base_metrics = base_metrics.append(basic_row, ignore_index=True)\n",
    "        advanced_row = get_advanced_metrics(selector, returns, ndx_returns, risk_free_rate)\n",
    "        advanced_metrics = advanced_metrics.append(advanced_row, ignore_index=True)\n",
    "    except Exception as e:\n",
    "        print(f'Cannot build the portfolio for the selector {selector}: {str(e)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tabulate(base_metrics, headers='keys', tablefmt='psql')) \n",
    "print(tabulate(advanced_metrics, headers='keys', tablefmt='psql')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tabulate(advanced_metrics, headers='keys', tablefmt='psql')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Weights Schema\n",
    "In inverse volatility strategy the risk is measured with volatility, and assets are weighted in inverse proportion to their risk. An inverse volatility weighted portfolio is one in which highly volatile assets are assigned smaller weights and low volatile assets are allotted larger weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reinitialization\n",
    "base_metrics = pd.DataFrame(columns=['Portfolio Title', 'Annualized Returns', 'Annualized Volatility'])\n",
    "advanced_metrics = pd.DataFrame(columns=['Portfolio Title', 'Sharpe Ratio', 'MDD', 'CL', 'Var 90', 'Var 95', 'Var 99', 'IR', 'M2'])\n",
    "portfolios_selector_history = {}\n",
    "portfolios_analysis = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weekly_portfolio_returns_inverse_volatility(window_returns, days):\n",
    "    \n",
    "    returns = []\n",
    "    left_the_market = []\n",
    "    title_volatility = {}\n",
    "\n",
    "    # Get past returns - decide a priori weights\n",
    "    titles = list(window_returns.columns)\n",
    "    nasdaq100_past_returns = nasdaq100_returns[titles].iloc[days - 7 : ROLLING_WINDOW_SIZE + days - 7]\n",
    "    for title in titles:\n",
    "        title_returns = nasdaq100_past_returns[title] \n",
    "        title_volatility[title] = 1 / title_returns.std()\n",
    "\n",
    "    for index, row in window_returns.iterrows():\n",
    "        daily_return = 0\n",
    "        total_volatility = 0\n",
    "\n",
    "        # Get total volatility\n",
    "        for title, value in row.items():\n",
    "            if math.isnan(value):\n",
    "                if title in left_the_market:\n",
    "                    pass\n",
    "                else:\n",
    "                    missing_price = closing_prices_removed_titles.iloc[index][title]\n",
    "                    if math.isnan(missing_price):\n",
    "                        if title in title_out_of_the_market.keys():\n",
    "                            total_volatility += title_volatility[title]\n",
    "                        else:\n",
    "                            raise Exception(f'Cannot find the closing/acquisition price of {title}')   \n",
    "                        left_the_market.append(title)\n",
    "                    else:\n",
    "                        total_volatility += title_volatility[title]\n",
    "            else:\n",
    "                 total_volatility += title_volatility[title]\n",
    "\n",
    "        for title, value in row.items():\n",
    "            if math.isnan(value):\n",
    "                if title in left_the_market:\n",
    "                    pass\n",
    "                else:\n",
    "                    missing_price = closing_prices_removed_titles.iloc[index][title]\n",
    "                    if math.isnan(missing_price):\n",
    "                        missing_price = title_out_of_the_market[title]\n",
    "                        last_closing_price = closing_prices_removed_titles.iloc[index - 1][title]\n",
    "                        missing_return = np.log(missing_price) - np.log(last_closing_price)\n",
    "                        daily_return += missing_return * (title_volatility[title] / total_volatility)\n",
    "                        left_the_market.append(title)\n",
    "                    else:\n",
    "                        last_closing_price = closing_prices_removed_titles.iloc[index - 1][title]\n",
    "                        missing_return = np.log(missing_price) - np.log(last_closing_price)\n",
    "                        daily_return += missing_return * (title_volatility[title] / total_volatility)\n",
    "            else:\n",
    "                 daily_return += value * (title_volatility[title] / total_volatility)\n",
    "\n",
    "        returns.append(daily_return)\n",
    "            \n",
    "    return returns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def portfolio_builder_inverse_volatility(selector):\n",
    "    portfolio_returns = []\n",
    "    portfolio = pd.DataFrame(columns=['Dates'] + [f'Title{i}' for i in range(1 , NUMBER_OF_TITLES + 1)] + ['Returns'])\n",
    "    portfolio_history = pd.DataFrame(columns=['Dates', 'Title', 'r2', 'specific_risk', 'beta', 'alpha', 'alpha_significance', 'absolute_returns'])\n",
    "\n",
    "    titles, values, _ = portfolio_ranked(selector, 0)\n",
    "    portfolio_history = portfolio_history.append(values, ignore_index=True)\n",
    "       \n",
    "    days_range = nasdaq100_returns.shape[0] - ROLLING_WINDOW_SIZE\n",
    "    for days in range(7, days_range, 7):\n",
    "\n",
    "        nasdaq100_window_returns = nasdaq100_returns[titles].iloc[ROLLING_WINDOW_SIZE + days - 7 : ROLLING_WINDOW_SIZE + days]\n",
    "\n",
    "        tmp_returns = get_weekly_portfolio_returns_inverse_volatility(nasdaq100_window_returns, days)\n",
    "        portfolio_returns = portfolio_returns + tmp_returns\n",
    "\n",
    "        portfolio_row = {'Dates': nasdaq100_returns.iloc[ROLLING_WINDOW_SIZE + days]['Dates']}\n",
    "        portfolio_row.update({f'Title{i}': titles[i - 1] for i in range(1, NUMBER_OF_TITLES + 1)})\n",
    "        portfolio = portfolio.append(portfolio_row, ignore_index=True)\n",
    "        titles, values, _ = portfolio_ranked(selector, days)\n",
    "        portfolio_history = portfolio_history.append(values, ignore_index=True)\n",
    "\n",
    "    portfolio_history = portfolio_history[:-NUMBER_OF_TITLES]\n",
    "    dates = np.array(portfolio['Dates'])\n",
    "    dates = np.repeat(dates, NUMBER_OF_TITLES)\n",
    "    portfolio_history['Dates'] = dates\n",
    "    return portfolio, portfolio_returns, portfolio_history\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for selector in selectors:\n",
    "    try:\n",
    "        print(f'Buildindg {selector} portfolio')        \n",
    "\n",
    "        portfolio, returns, history = portfolio_builder_inverse_volatility(selector)\n",
    "        \n",
    "        portfolios_selector_history[selector] = history\n",
    "        portfolios_analysis[selector] = returns\n",
    "\n",
    "        basic_row = get_base_metrics(selector, returns)\n",
    "        base_metrics = base_metrics.append(basic_row, ignore_index=True)\n",
    "        advanced_row = get_advanced_metrics(selector, returns, ndx_returns, risk_free_rate)\n",
    "        advanced_metrics = advanced_metrics.append(advanced_row, ignore_index=True)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'Cannot build the portfolio for the selector {selector}: {str(e)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tabulate(base_metrics, headers='keys', tablefmt='psql')) \n",
    "print(tabulate(advanced_metrics, headers='keys', tablefmt='psql')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple return vs Log returns\n",
    "Here we transform log returns to simple returns and see how portfolios returns change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reinitialization\n",
    "base_metrics = pd.DataFrame(columns=['Portfolio Title', 'Annualized Returns', 'Annualized Volatility'])\n",
    "advanced_metrics = pd.DataFrame(columns=['Portfolio Title', 'Sharpe Ratio', 'MDD', 'CL', 'Var 90', 'Var 95', 'Var 99', 'IR', 'M2'])\n",
    "portfolios_selector_history = {}\n",
    "portfolios_analysis = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weekly_portfolio_returns_with_simple_returns(window_returns):\n",
    "    \n",
    "    #Apply the conversion\n",
    "    window_returns = np.exp(window_returns) - 1\n",
    "\n",
    "    returns = []\n",
    "    left_the_market = []\n",
    "    for index, row in window_returns.iterrows():\n",
    "        portfolio_components_number = NUMBER_OF_TITLES\n",
    "        daily_return = 0\n",
    "        for title, value in row.items():\n",
    "            if math.isnan(value):\n",
    "                if title in left_the_market:\n",
    "                    portfolio_components_number -= 1\n",
    "                else:\n",
    "                    missing_price = closing_prices_removed_titles.iloc[index][title]\n",
    "                    if math.isnan(missing_price):\n",
    "                        if title in title_out_of_the_market.keys():\n",
    "                            missing_price = title_out_of_the_market[title]\n",
    "                            last_closing_price = closing_prices_removed_titles.iloc[index - 1][title]\n",
    "                            missing_return = (missing_price - last_closing_price) / last_closing_price\n",
    "                            daily_return += missing_return\n",
    "                        else:\n",
    "                            raise Exception(f'Cannot find the closing/acquisition price of {title}')   \n",
    "                        left_the_market.append(title)\n",
    "                    else:\n",
    "                        last_closing_price = closing_prices_removed_titles.iloc[index - 1][title]\n",
    "                        missing_return = (missing_price - last_closing_price) / last_closing_price\n",
    "                        daily_return += missing_return\n",
    "            else:\n",
    "                 daily_return += value\n",
    "        returns.append(daily_return / portfolio_components_number)  \n",
    "    return returns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def portfolio_builder_with_simple_returns(selector):\n",
    "    portfolio_returns = []\n",
    "    portfolio = pd.DataFrame(columns=['Dates'] + [f'Title{i}' for i in range(1 , NUMBER_OF_TITLES + 1)] + ['Returns'])\n",
    "    portfolio_history = pd.DataFrame(columns=['Dates', 'Title', 'r2', 'specific_risk', 'beta', 'alpha', 'alpha_significance', 'absolute_returns'])\n",
    "\n",
    "    titles, values, _ = portfolio_ranked(selector, 0)\n",
    "    portfolio_history = portfolio_history.append(values, ignore_index=True)\n",
    "       \n",
    "    days_range = nasdaq100_returns.shape[0] - ROLLING_WINDOW_SIZE\n",
    "    for days in range(7, days_range, 7):\n",
    "\n",
    "        nasdaq100_window_returns = nasdaq100_returns[titles].iloc[ROLLING_WINDOW_SIZE + days - 7 : ROLLING_WINDOW_SIZE + days]\n",
    "\n",
    "        tmp_returns = get_weekly_portfolio_returns_with_simple_returns(nasdaq100_window_returns)\n",
    "        portfolio_returns = portfolio_returns + tmp_returns\n",
    "\n",
    "        portfolio_row = {'Dates': nasdaq100_returns.iloc[ROLLING_WINDOW_SIZE + days]['Dates']}\n",
    "        portfolio_row.update({f'Title{i}': titles[i - 1] for i in range(1, NUMBER_OF_TITLES + 1)})\n",
    "        portfolio = portfolio.append(portfolio_row, ignore_index=True)\n",
    "        titles, values, _ = portfolio_ranked(selector, days)\n",
    "        portfolio_history = portfolio_history.append(values, ignore_index=True)\n",
    "\n",
    "    portfolio_history = portfolio_history[:-NUMBER_OF_TITLES]\n",
    "    dates = np.array(portfolio['Dates'])\n",
    "    dates = np.repeat(dates, NUMBER_OF_TITLES)\n",
    "    portfolio_history['Dates'] = dates\n",
    "    return portfolio, portfolio_returns, portfolio_history\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for selector in selectors:\n",
    "    try:\n",
    "        print(f'Buildindg {selector} portfolio')        \n",
    "\n",
    "        portfolio, returns, history = portfolio_builder_with_simple_returns(selector)\n",
    "        \n",
    "        portfolios_selector_history[selector] = history\n",
    "        portfolios_analysis[selector] = returns\n",
    "\n",
    "        basic_row = get_base_metrics(selector, returns)\n",
    "        base_metrics = base_metrics.append(basic_row, ignore_index=True)\n",
    "        advanced_row = get_advanced_metrics(selector, returns, ndx_returns, risk_free_rate)\n",
    "        advanced_metrics = advanced_metrics.append(advanced_row, ignore_index=True)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'Cannot build the portfolio for the selector {selector}: {str(e)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the Nasdaq-100 to our tables\n",
    "ndx_simple_returns = np.exp(ndx_returns) - 1\n",
    "basic_row = get_base_metrics('Nasdaq-100', ndx_simple_returns)\n",
    "base_metrics = base_metrics.append(basic_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tabulate(base_metrics, headers='keys', tablefmt='psql')) \n",
    "print(tabulate(advanced_metrics, headers='keys', tablefmt='psql')) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "76138418a387bad0f053fbad3fc8f4bba023084ab7c4cba1783c6f70bccd9aae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
